{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus = pd.read_csv(r\"aji-Arabic_corpus.csv\")\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text'],Corpus['targe'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert into Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(Corpus['text'])\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  97.33333333333334\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.9630    0.9811    0.9720        53\n",
      "    Economic     0.9310    0.9818    0.9558        55\n",
      "    Politics     0.9833    0.9077    0.9440        65\n",
      "     Science     1.0000    1.0000    1.0000        58\n",
      "       Sport     0.9857    1.0000    0.9928        69\n",
      "\n",
      "    accuracy                         0.9733       300\n",
      "   macro avg     0.9726    0.9741    0.9729       300\n",
      "weighted avg     0.9739    0.9733    0.9731       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_NB, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocchio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NearestCentroid()\n",
    "model.fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_RC = model.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.8704    0.9216    0.8952        51\n",
      "    Economic     0.6724    1.0000    0.8041        39\n",
      "    Politics     1.0000    0.6897    0.8163        87\n",
      "     Science     1.0000    1.0000    1.0000        58\n",
      "       Sport     0.9286    1.0000    0.9630        65\n",
      "\n",
      "    accuracy                         0.8967       300\n",
      "   macro avg     0.8943    0.9222    0.8957       300\n",
      "weighted avg     0.9199    0.8967    0.8954       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_RC, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting and Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_BB = model.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.9630    0.9286    0.9455        56\n",
      "    Economic     0.8793    0.8947    0.8870        57\n",
      "    Politics     0.9333    0.8750    0.9032        64\n",
      "     Science     0.9310    1.0000    0.9643        54\n",
      "       Sport     0.9571    0.9710    0.9640        69\n",
      "\n",
      "    accuracy                         0.9333       300\n",
      "   macro avg     0.9328    0.9339    0.9328       300\n",
      "weighted avg     0.9337    0.9333    0.9330       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_BB, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting is a Ensemble learning meta-algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BaggingClassifier(KNeighborsClassifier())\n",
    "model.fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_Bag = model.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.8704    0.9592    0.9126        49\n",
      "    Economic     0.8276    0.9412    0.8807        51\n",
      "    Politics     0.9333    0.7671    0.8421        73\n",
      "     Science     1.0000    0.9831    0.9915        59\n",
      "       Sport     0.9571    0.9853    0.9710        68\n",
      "\n",
      "    accuracy                         0.9200       300\n",
      "   macro avg     0.9177    0.9272    0.9196       300\n",
      "weighted avg     0.9236    0.9200    0.9188       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_Bag, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_KNN = model.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.8889    0.9231    0.9057        52\n",
      "    Economic     0.8276    0.9231    0.8727        52\n",
      "    Politics     0.9000    0.7826    0.8372        69\n",
      "     Science     1.0000    0.9831    0.9915        59\n",
      "       Sport     0.9571    0.9853    0.9710        68\n",
      "\n",
      "    accuracy                         0.9167       300\n",
      "   macro avg     0.9147    0.9194    0.9156       300\n",
      "weighted avg     0.9181    0.9167    0.9159       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_KNN, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_SVM = model.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.9630    1.0000    0.9811        52\n",
      "    Economic     0.9655    0.9825    0.9739        57\n",
      "    Politics     0.9667    0.9355    0.9508        62\n",
      "     Science     1.0000    1.0000    1.0000        58\n",
      "       Sport     1.0000    0.9859    0.9929        71\n",
      "\n",
      "    accuracy                         0.9800       300\n",
      "   macro avg     0.9790    0.9808    0.9798       300\n",
      "weighted avg     0.9801    0.9800    0.9799       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_SVM, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_DT = model.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.6852    0.6852    0.6852        54\n",
      "    Economic     0.7586    0.7857    0.7719        56\n",
      "    Politics     0.8167    0.6712    0.7368        73\n",
      "     Science     0.7414    0.9348    0.8269        46\n",
      "       Sport     0.9286    0.9155    0.9220        71\n",
      "\n",
      "    accuracy                         0.7933       300\n",
      "   macro avg     0.7861    0.7985    0.7886       300\n",
      "weighted avg     0.7971    0.7933    0.7917       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_DT, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Random Field (CRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(Train_X_Tfidf, Train_Y)\n",
    "predictions_DT = model.predict(Test_X_Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Art     0.7407    0.6667    0.7018        60\n",
      "    Economic     0.7759    0.7500    0.7627        60\n",
      "    Politics     0.8167    0.7778    0.7967        63\n",
      "     Science     0.7586    0.9565    0.8462        46\n",
      "       Sport     0.9286    0.9155    0.9220        71\n",
      "\n",
      "    accuracy                         0.8100       300\n",
      "   macro avg     0.8041    0.8133    0.8059       300\n",
      "weighted avg     0.8109    0.8100    0.8082       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Art', 'Economic', 'Politics', 'Science', 'Sport']\n",
    "report=classification_report(predictions_DT, Test_Y, target_names=target_names, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
